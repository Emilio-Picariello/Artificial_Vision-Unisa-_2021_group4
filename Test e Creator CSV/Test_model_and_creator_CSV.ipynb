{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Test_model.ipynb","provenance":[],"collapsed_sections":["VMQ53qHf0JTj","szyfmjLX2_yq"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZJ90Ar1rAJb9"},"source":["Cambiare i Path in base alle locazioni dei file desiderati"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4FR9lnpoBZd","executionInfo":{"status":"ok","timestamp":1610031274362,"user_tz":-60,"elapsed":24793,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"9a5bbdd6-3683-433b-87b7-c7b0c098c7b3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RuulsFR6nKrS","executionInfo":{"status":"ok","timestamp":1610039260034,"user_tz":-60,"elapsed":856,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 128\n","IMAGE_SIZE = [96, 96]"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VMQ53qHf0JTj"},"source":["#### Test model on Test Set "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKfJnIPPnKrT","executionInfo":{"status":"ok","timestamp":1610039442089,"user_tz":-60,"elapsed":1686,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"371f8997-21c8-4f2b-f6ca-cff7187cf19b"},"source":["import tensorflow as tf\n","from functools import partial\n","\n","FILENAMES1=tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group6/\" + \"*.tfrecords\" )\n","FILENAMES2= tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group7/\" + \"*.tfrecords\" )\n","\n","FILENAMES=FILENAMES1 + FILENAMES2\n","\n","TEST_FILENAMES = FILENAMES\n","\n","print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Test TFRecord Files: 50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"duKEJWY1nKrU","executionInfo":{"status":"ok","timestamp":1610039445866,"user_tz":-60,"elapsed":1358,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["\n","def decode_image(image_raw):\n","    image_shape = tf.stack([96, 96, 3])\n","    image = tf.io.decode_raw(image_raw, tf.uint8)\n","    image = tf.cast(image, tf.float32)\n","    image = tf.reshape(image, image_shape)\n","    \n","    return image\n","\n","def read_tfrecord(example, labeled):\n","    tf.compat.v1.enable_eager_execution()\n","    tfrecord_format = (\n","        {\n","            \"label_regr\": tf.io.FixedLenFeature([],tf.float32),\n","            \"label_class\": tf.io.FixedLenFeature([101],tf.int64),\n","            \"label_order\" : tf.io.FixedLenFeature([101],tf.int64),\n","            \"image\" : tf.io.FixedLenFeature([],tf.string),\n","        }\n","        if labeled\n","        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example[\"image\"])\n","    if labeled: \n","        label = example[\"label_class\"]\n","        return image, label\n","    return image\n"," "],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8x49qUJnKrW","executionInfo":{"status":"ok","timestamp":1610039451057,"user_tz":-60,"elapsed":1336,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["\n","def load_dataset(filenames, labeled=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(\n","        filenames\n","    )  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(\n","        ignore_order\n","    )  # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n","    )\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Db_QC9nNnKrX","executionInfo":{"status":"ok","timestamp":1610039455216,"user_tz":-60,"elapsed":1278,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["\n","def get_dataset(filenames, labeled=True):\n","    dataset = load_dataset(filenames, labeled=labeled)\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-tAzy8w0rUx"},"source":["from google.colab.patches import cv2_imshow\n","\n","def show_batch(image_batch,label_batch):\n","    count=0\n","    for n in range(0,len(image_batch)):\n","        cv2_imshow(image_batch[n])\n","        print(\"Label:\" + str(label_batch[n])) \n","\n","test_dataset = get_dataset(TEST_FILENAMES, labeled=True)\n","\n","count=0\n","for image_batch,label_batch in iter(test_dataset):\n","  count=count+len(image_batch)\n","  print(str(count) + \" di 1014120\")\n","print(\"Number of images for Test: \" + str(count))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZKHAR5P1U8w"},"source":["## Show image and label of single batch in Test Set \r\n","\r\n","image_batch,label_batch= next(iter(test_dataset))\r\n","show_batch(image_batch.numpy(),label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUGHp_Qx16a_","executionInfo":{"status":"ok","timestamp":1610039933373,"user_tz":-60,"elapsed":3893,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["## load model \r\n","from tensorflow import keras\r\n","\r\n","model=keras.models.load_model(\"/content/drive/MyDrive/Final_Artificial_Vision/CNN/vggFace_classificatore_full1.h5\") "],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTEDTBWv2gUD","executionInfo":{"status":"ok","timestamp":1610039939146,"user_tz":-60,"elapsed":816,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["# CUSTOM METRIC\r\n","\r\n","import keras.backend as K\r\n","from tensorflow.keras.metrics import mean_absolute_error\r\n","\r\n","def mae(y_true, y_pred):\r\n","\r\n","  sum=0\r\n","  y_true = K.cast(y_true, y_pred.dtype)\r\n","\r\n","  ages_true = tf.map_fn(lambda true: K.argmax(true), y_true, dtype=tf.int64)\r\n","  ages_pred = tf.map_fn(lambda pred: K.argmax(pred), y_pred, dtype=tf.int64)\r\n","\r\n","  for i in range(0,len(ages_true)):\r\n","    err=abs(ages_true[i]-ages_pred[i])\r\n","    sum=sum+err\r\n","  \r\n","  return sum"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"NekLFyKS2kg5"},"source":["#Test our model\r\n","\r\n","count=0\r\n","sum=0\r\n","for image_batch,label_batch in iter(test_dataset):\r\n","  count=count+len(image_batch)\r\n","  #ypred.extend(model.predict(image_batch))\r\n","  sum=sum+mae(label_batch,model.predict(image_batch))\r\n","  print(str(count) + \" di 1014120\")\r\n","  #tf.print(mae_temp)\r\n","  print(\"MAE \" + str(count)+ \" di 1014120 : \")\r\n","  tf.print(sum/count)\r\n","print(\"FINAL MAE: \")\r\n","tf.print(sum/count)\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"szyfmjLX2_yq"},"source":["#### Create CSV on Test images \r\n","\r\n","To create a csv you must pass image as TFRecords \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GecZaXXh3Keo","executionInfo":{"status":"ok","timestamp":1610040726618,"user_tz":-60,"elapsed":851,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"65ad8dfb-25ef-4de6-fb3b-ecd495ecbd95"},"source":["import tensorflow as tf\n","from functools import partial\n","\n","TEST_FILENAMES = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/testset/\" + \"*.tfrecords\" )\n","\n","print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Test TFRecord Files: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuisHsj-ut8c","executionInfo":{"status":"ok","timestamp":1610040728699,"user_tz":-60,"elapsed":844,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["import tensorflow as tf\n","import keras.backend as K\n","import numpy as np \n","\n","def read_tfrecord_test(example,labeled):\n","    tfrecord_format = (\n","        {\n","            \"image\" : tf.io.FixedLenFeature([],tf.string),\n","            \"relative_path\" : tf.io.FixedLenFeature([],tf.string),\n","        }\n","        if labeled\n","        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example[\"image\"])\n","    path=example[\"relative_path\"]\n","    return image,path\n"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvC5fLdX359f","executionInfo":{"status":"ok","timestamp":1610040731555,"user_tz":-60,"elapsed":842,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["\n","def load_dataset(filenames, labeled=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(\n","        filenames\n","    )  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(\n","        ignore_order\n","    )  # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord_test, labeled=labeled), num_parallel_calls=AUTOTUNE\n","    )\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset\n"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"CywJ6ScCnKrY"},"source":["from google.colab.patches import cv2_imshow\n","\n","test_dataset = get_dataset(TEST_FILENAMES, labeled=True)\n","\n","count=0\n","for image_batch,path_batch in iter(test_dataset):\n","  count=count+len(image_batch)\n","  print(str(count) + \" di 168872\")\n","print(\"Number of Test Images: \" + str(count))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9uFwSwB5U-O","executionInfo":{"status":"ok","timestamp":1610040798476,"user_tz":-60,"elapsed":803,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["def show_batch(image_batch,path_batch):\r\n","    count=0\r\n","    for n in range(0,len(image_batch)):\r\n","        cv2_imshow(image_batch[n])\r\n","        print(\"Path:\" + str(path_batch[n].decode()))\r\n"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIe1aQH-EE-p"},"source":["image_batch,path_batch= next(iter(test_dataset))\r\n","show_batch(image_batch.numpy(),path_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f99DGckgAwJP","executionInfo":{"status":"ok","timestamp":1610040824887,"user_tz":-60,"elapsed":3320,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["model=keras.models.load_model(\"/content/drive/MyDrive/Final_Artificial_Vision/CNN/vggFace_classificatore_full1.h5\")  "],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGRoTFo7pyH-","executionInfo":{"status":"ok","timestamp":1610040858191,"user_tz":-60,"elapsed":1219,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["import csv\r\n","\r\n","def csv_result(path,label):\r\n","    with open('result_VGGFace2.csv', 'a', newline='') as file:\r\n","        writer = csv.writer(file)\r\n","        writer.writerow([path, label])\r\n"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCeSPEu4Ekry","executionInfo":{"status":"ok","timestamp":1610040859862,"user_tz":-60,"elapsed":1075,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["def create_csv(predict_batch,path_batch):\r\n","\r\n","  for i in range(0,len(path_batch)):\r\n","    label=predict_batch[i].argmax(axis=0)\r\n","    path=path_batch[i].numpy().decode()\r\n","    csv_result(path,label)\r\n","\r\n"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jolb1i4_ESmo"},"source":["count=0\r\n","for image_batch,path_batch in iter(test_dataset):\r\n","  count=count+len(image_batch)\r\n","  create_csv(model.predict(image_batch),path_batch)\r\n","  print(str(count) + \" di 168872\" )\r\n","\r\n","print(\" Number of images saved: \" + str(count))"],"execution_count":null,"outputs":[]}]}