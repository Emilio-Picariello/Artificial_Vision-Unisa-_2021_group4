{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine_tuning_smart_Daniele2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyOiUgJGpYR2","executionInfo":{"status":"ok","timestamp":1610007300644,"user_tz":-60,"elapsed":23965,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}},"outputId":"bfa83733-842b-471f-d3c2-8555be5c3e26"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nmejxv_uozO7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610007305303,"user_tz":-60,"elapsed":2730,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}},"outputId":"b08573a2-22fc-4c41-9f04-a52531e24efb"},"source":["import tensorflow as tf\n","from functools import partial\n","import matplotlib.pyplot as plt\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LgfEH4V-pOq7","executionInfo":{"status":"ok","timestamp":1610007313716,"user_tz":-60,"elapsed":739,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 256\n","IMAGE_SIZE = [96, 96]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"beuPhDjYpsUy","executionInfo":{"status":"ok","timestamp":1610007318435,"user_tz":-60,"elapsed":3416,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}},"outputId":"1283592d-9ff7-4f24-f544-bce9e4d17c70"},"source":["FILENAMES1 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/\" + \"*.tfrecords\")\n","FILENAMES2 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/\" + \"*.tfrecords\")\n","FILENAMES3 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/\" + \"*.tfrecords\")\n","FILENAMES4 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/\" + \"*.tfrecords\")\n","FILENAMES5 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group5/\" + \"*.tfrecords\")\n","FILENAMES6 = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_splitted_by_age_2000/\" + \"*.tfrecords\")\n","UTKFACE = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/extrautkface/UTKFace.tfrecords\")\n","\n","FILENAMES = FILENAMES1 + FILENAMES2 + UTKFACE + FILENAMES3 +FILENAMES4\n","split_ind = int(0.77 * len(FILENAMES))\n","print(len(FILENAMES))\n","TRAINING_FILENAMES, VALID_FILENAMES = FILENAMES[:split_ind], FILENAMES[split_ind:]\n","TEST_FILENAMES = tf.io.gfile.glob(\"/content/drive/MyDrive/Final_Artificial_Vision/test_tf_record_alignement/test_with_resize.tfrecords\")\n","\n","print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n","print(TRAINING_FILENAMES)\n","print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n","print(VALID_FILENAMES)\n","print(\"Test TFRecord Files:\", len(TEST_FILENAMES))\n","print(TEST_FILENAMES)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["81\n","Train TFRecord Files: 62\n","['/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part1.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part10.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part2.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part3.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part4.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part5.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part6.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part7.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part8.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part9.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part11.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part12.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part13.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part14.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part15.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part16.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part17.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part18.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part19.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group1/dataset_part20.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part21.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part22.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part23.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part24.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part25.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part26.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part27.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part28.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part29.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part30.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part31.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part32.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part33.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part34.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part35.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part36.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part37.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part38.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part39.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group2/dataset_part40.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/extrautkface/UTKFace.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part41.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part42.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part43.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part44.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part45.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part46.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part47.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part48.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part49.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part50.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part51.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part52.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part53.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part54.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part55.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part56.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part57.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part58.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part59.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group3/dataset_part60.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part61.tfrecords']\n","Validation TFRecord Files: 19\n","['/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part62.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part63.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part64.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part65.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part66.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part67.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part68.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part69.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part70.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part71.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part72.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part73.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part74.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part75.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part76.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part77.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part78.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part79.tfrecords', '/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/group4/dataset_part80.tfrecords']\n","Test TFRecord Files: 1\n","['/content/drive/MyDrive/Final_Artificial_Vision/test_tf_record_alignement/test_with_resize.tfrecords']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fk0m0Xnuj0xh"},"source":["!pip install git+https://github.com/rcmalli/keras-vggface.git\r\n","!pip install keras-vggface\r\n","!pip install keras_applications"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfPVY27EqssK","executionInfo":{"status":"ok","timestamp":1610007405986,"user_tz":-60,"elapsed":763,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["def decode_image(image):\n","    #image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.io.decode_raw(image, tf.uint8)\n","    image = tf.cast(image, tf.float32)\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n","    return image\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LZRknx4rE22","executionInfo":{"status":"ok","timestamp":1610007407224,"user_tz":-60,"elapsed":774,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["def read_tfrecord(example, labeled):\n","    tfrecord_format = (\n","        {\n","            \"image\": tf.io.FixedLenFeature([], tf.string),\n","            \"label_class\": tf.io.FixedLenFeature([101],tf.int64),\n","            \"label_regr_int\": tf.io.FixedLenFeature([], tf.int64),\n","        }\n","        if labeled\n","        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example[\"image\"])\n","    if labeled:\n","        #label = tf.cast(example[\"label_regr_int\"], tf.int64)\n","        label = example[\"label_class\"]\n","        print(str(label))\n","        return image, label\n","    return image"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"b82zuMVIrbSY","executionInfo":{"status":"ok","timestamp":1610007410082,"user_tz":-60,"elapsed":708,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["def load_dataset(filenames, labeled=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(\n","        filenames\n","    )  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(\n","        ignore_order\n","    )  # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n","    )\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"96EIqPGfrpbl","executionInfo":{"status":"ok","timestamp":1610007413380,"user_tz":-60,"elapsed":736,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["def get_dataset(filenames, labeled=True):\n","    dataset = load_dataset(filenames, labeled=labeled)\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PS34NXZTr7u6"},"source":["from google.colab.patches import cv2_imshow\n","train_dataset = get_dataset(TRAINING_FILENAMES)\n","valid_dataset = get_dataset(VALID_FILENAMES)\n","test_dataset = get_dataset(TEST_FILENAMES, labeled=True)\n","\n","image_batch, label_batch = next(iter(test_dataset))\n","\n","\n","def show_batch(image_batch, label_batch):\n","    plt.figure(figsize=(10, 10))\n","    for n in range(1):\n","        ax = plt.subplot(5, 5, n + 1)\n","        plt.imshow(image_batch[n] / 255.0)\n","        plt.title(str(label_batch[n]))\n","        plt.axis(\"off\")\n","\n","\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXfvyVjceLa_","executionInfo":{"status":"ok","timestamp":1610007422886,"user_tz":-60,"elapsed":3582,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["# CUSTOM METRIC\r\n","\r\n","import keras.backend as K\r\n","from tensorflow.keras.metrics import mean_absolute_error\r\n","\r\n","@tf.function\r\n","def mae(y_true, y_pred):\r\n","  y_true = K.cast(y_true, y_pred.dtype)\r\n","\r\n","  ages_true = tf.map_fn(lambda true: K.argmax(true), y_true, dtype=tf.int64)\r\n","  ages_pred = tf.map_fn(lambda pred: K.argmax(pred), y_pred, dtype=tf.int64)\r\n","\r\n","  #fn_output_signature da usare nel caso map_fn non funzioni\r\n","\r\n","  return mean_absolute_error(ages_true, ages_pred)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZQl2-P7ukSq","executionInfo":{"status":"ok","timestamp":1610035978999,"user_tz":-60,"elapsed":972,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}},"outputId":"a6a10dce-ec1d-45e5-e075-658a73e81061"},"source":["#Define model VGGFace-VGG16 Classification\n","from keras_vggface.vggface import VGGFace\n","from keras.engine import  Model\n","from keras.layers import Flatten, Dense, Input, Dropout\n","vgg_model = VGGFace(weights=None, include_top=False, input_shape=(96, 96, 3))\n","\n","\"\"\"\n","# Freeze four convolution blocks\n","for layer in vgg_model.layers[:15]:\n","    layer.trainable = False\n","\n","#don't train existing weights\n","for layer in vgg_model.layers:\n","  layer.trainable = False\n","\"\"\"\n","x = vgg_model.get_layer('pool5').output\n","x = Flatten()(x) # Flatten dimensions to for use in FC layers\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.2)(x) # Dropout layer to reduce overfitting\n","x = Dense(512, activation='relu')(x)\n","out = Dense(101, activation= 'softmax')(x) \n","transfer_model = Model(vgg_model.input, out)\n","\n","\"\"\"\n","# Loads the weights of pretraining\n","checkpoint_path = '/content/drive/MyDrive/Final_Artificial_Vision/CNN/vggFace_classificatore2.h5'\n","transfer_model.load_weights(checkpoint_path)\n","\"\"\"\n","# Loads the weights of full model\n","checkpoint_path = '/content/drive/MyDrive/Final_Artificial_Vision/CNN/vggFace_classificatore_full2.h5'\n","transfer_model.load_weights(checkpoint_path)\n","\n","# Visualize the network\n","for i, layer in enumerate(transfer_model.layers):\n","    print(i, layer.name, layer.trainable)\n","\n","\n","transfer_model.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["0 input_9 True\n","1 conv1_1 True\n","2 conv1_2 True\n","3 pool1 True\n","4 conv2_1 True\n","5 conv2_2 True\n","6 pool2 True\n","7 conv3_1 True\n","8 conv3_2 True\n","9 conv3_3 True\n","10 pool3 True\n","11 conv4_1 True\n","12 conv4_2 True\n","13 conv4_3 True\n","14 pool4 True\n","15 conv5_1 True\n","16 conv5_2 True\n","17 conv5_3 True\n","18 pool5 True\n","19 flatten_8 True\n","20 dense_24 True\n","21 dropout_8 True\n","22 dense_25 True\n","23 dense_26 True\n","Model: \"model_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_9 (InputLayer)         [(None, 96, 96, 3)]       0         \n","_________________________________________________________________\n","conv1_1 (Conv2D)             (None, 96, 96, 64)        1792      \n","_________________________________________________________________\n","conv1_2 (Conv2D)             (None, 96, 96, 64)        36928     \n","_________________________________________________________________\n","pool1 (MaxPooling2D)         (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","conv2_1 (Conv2D)             (None, 48, 48, 128)       73856     \n","_________________________________________________________________\n","conv2_2 (Conv2D)             (None, 48, 48, 128)       147584    \n","_________________________________________________________________\n","pool2 (MaxPooling2D)         (None, 24, 24, 128)       0         \n","_________________________________________________________________\n","conv3_1 (Conv2D)             (None, 24, 24, 256)       295168    \n","_________________________________________________________________\n","conv3_2 (Conv2D)             (None, 24, 24, 256)       590080    \n","_________________________________________________________________\n","conv3_3 (Conv2D)             (None, 24, 24, 256)       590080    \n","_________________________________________________________________\n","pool3 (MaxPooling2D)         (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","conv4_1 (Conv2D)             (None, 12, 12, 512)       1180160   \n","_________________________________________________________________\n","conv4_2 (Conv2D)             (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","conv4_3 (Conv2D)             (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","pool4 (MaxPooling2D)         (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","conv5_1 (Conv2D)             (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","conv5_2 (Conv2D)             (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","conv5_3 (Conv2D)             (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","pool5 (MaxPooling2D)         (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 512)               2359808   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 101)               51813     \n","=================================================================\n","Total params: 17,388,965\n","Trainable params: 17,388,965\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H_x4Oj32Eqv_","executionInfo":{"status":"ok","timestamp":1610036001843,"user_tz":-60,"elapsed":740,"user":{"displayName":"DaniV 95","photoUrl":"","userId":"11967446588169256796"}}},"source":["from keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import ModelCheckpoint\n","checkpoint = ModelCheckpoint('/content/drive/MyDrive/Final_Artificial_Vision/CNN/vggFace_classificatore_full2.h5', monitor= 'val_mae', mode= 'min', save_weights_only=False, save_best_only = True, verbose= 1)\n","\n","from tensorflow.keras import layers, models, Model, optimizers\n","\n","transfer_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.CategoricalAccuracy(), mae])"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SIUEUIXu7rF"},"source":["#Train the model VGGFace-VGG16 Classification\n","history = transfer_model.fit(train_dataset, epochs=2, validation_data=valid_dataset, callbacks=[checkpoint])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hE41ZBf5gjiY"},"source":["#Plot the mae details\n","plt.plot(history.history['mae'])\n","plt.plot(history.history['val_mae'])"],"execution_count":null,"outputs":[]}]}