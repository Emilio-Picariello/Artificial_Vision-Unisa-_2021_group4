{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MobileNet_Training.ipynb","provenance":[],"collapsed_sections":["WIxWRo9ZnKrT","GvK8OYC2nKrY","dW_wWKfPnKrb"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4FR9lnpoBZd","executionInfo":{"status":"ok","timestamp":1610037387015,"user_tz":-60,"elapsed":23554,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"3fcf48d9-6d19-4fd4-d9f5-49e9b644f1ed"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZJBFD0BErK9w","executionInfo":{"status":"ok","timestamp":1610037387874,"user_tz":-60,"elapsed":2942,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["import os\r\n","\r\n","os.chdir('/content/drive/MyDrive/Final_Artificial_Vision/dataset_tf_parts/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuulsFR6nKrS","executionInfo":{"status":"ok","timestamp":1610037390765,"user_tz":-60,"elapsed":808,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 128\n","IMAGE_SIZE = [96, 96]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WIxWRo9ZnKrT"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKfJnIPPnKrT","executionInfo":{"status":"ok","timestamp":1610037394989,"user_tz":-60,"elapsed":3103,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"4cb500aa-2ca4-498b-e261-bdc1243c90a6"},"source":["import tensorflow as tf\n","\n","FILENAMES1 = tf.io.gfile.glob(\"group1/\" + \"*.tfrecords\" )\n","FILENAMES2= tf.io.gfile.glob(\"group2/\" + \"*.tfrecords\" )\n","FILENAMES3= tf.io.gfile.glob(\"extrautkface/\" + \"*.tfrecords\" )\n","FILENAMES4= tf.io.gfile.glob(\"group3/\" + \"*.tfrecords\" )\n","FILENAMES5= tf.io.gfile.glob(\"group4/\" + \"*.tfrecords\" )\n","FILENAMES6= tf.io.gfile.glob(\"group5/\" + \"*.tfrecords\" )\n","\n","FILENAMES=FILENAMES3+ FILENAMES1+FILENAMES2 + FILENAMES4 +FILENAMES5 +FILENAMES6\n","\n","split_ind = int(0.7 * len(FILENAMES))\n","TRAINING_FILENAMES, VALID_FILENAMES = FILENAMES[:split_ind], FILENAMES[split_ind:len(FILENAMES)-1]\n","\n","TEST_FILENAMES = FILENAMES[len(FILENAMES)-1:]\n","\n","print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n","print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n","print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train TFRecord Files: 70\n","Validation TFRecord Files: 30\n","Test TFRecord Files: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JGVSkznsnKrT"},"source":["### Decoding the data \n","\n","The images have to be converted to tensors so that it will be a valid input in our model.\n","As images utilize an RBG scale, we specify 3 channels.\n","\n"]},{"cell_type":"code","metadata":{"id":"duKEJWY1nKrU","executionInfo":{"status":"ok","timestamp":1610037663860,"user_tz":-60,"elapsed":974,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["import keras.backend as K\n","import numpy as np \n","\n","\n","def decode_image(image_raw):\n","    image_shape = tf.stack([96, 96, 3])\n","    image = tf.io.decode_raw(image_raw, tf.uint8)\n","    image = tf.cast(image, tf.float32)\n","    image = tf.reshape(image, image_shape)\n","    \n","    return image\n","\n","\n","def read_tfrecord(example, labeled):\n","    tf.compat.v1.enable_eager_execution()\n","    tfrecord_format = (\n","        {\n","            \"label_regr\": tf.io.FixedLenFeature([],tf.float32),\n","            \"label_class\": tf.io.FixedLenFeature([101],tf.int64),\n","            \"label_order\" : tf.io.FixedLenFeature([101],tf.int64),\n","            \"image\" : tf.io.FixedLenFeature([],tf.string),\n","        }\n","        if labeled\n","        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example[\"image\"])\n","    if labeled: \n","        label = example[\"label_class\"]\n","        return image, label\n","    return image\n"," "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wIESBfLXHmtd","executionInfo":{"status":"ok","timestamp":1610037581017,"user_tz":-60,"elapsed":790,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"fa85e01a-59fb-4d70-8d73-b2e8478b925f"},"source":["tf.version.VERSION"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.0'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"qbi50ttjnKrV"},"source":["### Functions to load Data\n","\n","Create functions to load data"]},{"cell_type":"code","metadata":{"id":"z8x49qUJnKrW","executionInfo":{"status":"ok","timestamp":1610038369930,"user_tz":-60,"elapsed":1037,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["from functools import partial\n","\n","def load_dataset(filenames, labeled=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(\n","        filenames\n","    )  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(\n","        ignore_order\n","    )  # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n","    )\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset\n"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zXdRX4fnKrW"},"source":["We define the following function to get our different datasets."]},{"cell_type":"code","metadata":{"id":"Db_QC9nNnKrX","executionInfo":{"status":"ok","timestamp":1610038374422,"user_tz":-60,"elapsed":1158,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["\n","def get_dataset(filenames, labeled=True):\n","    dataset = load_dataset(filenames, labeled=labeled)\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ska_-BdqtRwq","executionInfo":{"status":"ok","timestamp":1610038095951,"user_tz":-60,"elapsed":815,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["from keras.layers import Flatten, Dense, Input, Dropout\r\n","from tensorflow.keras import layers, models, Model, optimizers\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.callbacks import ModelCheckpoint\r\n","\r\n","def mobilenet_96_build(input_shape=(96,96,3), num_classes=101, weights=\"imagenet\"):\r\n","    global lr_reduce,checkpoint\r\n","    print(\"Building mobilenet 96\", input_shape, \"- num_classes\", num_classes, \"- weights\", weights)\r\n","    m1 = keras.applications.mobilenet_v2.MobileNetV2(input_shape, 0.75, include_top=True, weights=weights)\r\n","    features = m1.layers[-2].output\r\n","    x = keras.layers.Dense(num_classes, activation='softmax', use_bias=True, name='Logits')(features)\r\n","    model = keras.models.Model(m1.input, x)\r\n","    lr_reduce = ReduceLROnPlateau(monitor='val_mae', factor=0.6, patience=5, verbose=1, mode='auto', min_lr=5e-5)\r\n","    for l in model.layers: l.trainable = True\r\n","    return model, features"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqbNQhGmo6s_","executionInfo":{"status":"ok","timestamp":1610038003601,"user_tz":-60,"elapsed":954,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["from tensorflow import keras"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f4vZqn0o8XY","executionInfo":{"status":"ok","timestamp":1610038099308,"user_tz":-60,"elapsed":2058,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}},"outputId":"e3046d57-b4c3-4469-b256-f39efbccb1b1"},"source":["initial_model,features=mobilenet_96_build((96,96,3), 101)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Building mobilenet 96 (96, 96, 3) - num_classes 101 - weights imagenet\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LZs6KOrAnKrX"},"source":["### Loading Data"]},{"cell_type":"code","metadata":{"id":"CywJ6ScCnKrY"},"source":["from google.colab.patches import cv2_imshow\n","\n","\n","#Function to show image with relative label One-Hot Encoding\n","def show_batch(image_batch, label_batch):\n","    count=0\n","    for n in range(0,len(image_batch)):\n","        cv2_imshow(image_batch[n])\n","        label=label_batch[n]\n","        print(\"Label:\" + str(label))\n","        count=count+1\n","    print(count) \n","\n","train_dataset = get_dataset(TRAINING_FILENAMES)\n","valid_dataset = get_dataset(VALID_FILENAMES)\n","test_dataset = get_dataset(TEST_FILENAMES, labeled=False)\n","\n","count=0\n","for image_batch,label_batch in iter(train_dataset):\n","  count=count+len(image_batch)\n","  print(str(count) + \" di 1423313\")\n","print(\"Number of images for training is: \" + str(count))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMIK3lCmt2X_"},"source":["# Show image and label of a single batch in training set BATCH_SIZE=128\r\n","image_batch, label_batch = next(iter(train_dataset))\r\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GvK8OYC2nKrY"},"source":["## Building our model"]},{"cell_type":"code","metadata":{"id":"fWN915CNMOYk","executionInfo":{"status":"ok","timestamp":1610038992814,"user_tz":-60,"elapsed":1638,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["# CUSTOM METRIC\r\n","\r\n","import keras.backend as K\r\n","from tensorflow.keras.metrics import mean_absolute_error\r\n","\r\n","def mae(y_true, y_pred): \r\n","  y_true = K.cast(y_true, y_pred.dtype)\r\n","\r\n","  ages_true = tf.map_fn(lambda true: K.argmax(true), y_true, dtype=tf.int64)\r\n","  ages_pred = tf.map_fn(lambda pred: K.argmax(pred), y_pred, dtype=tf.int64)\r\n","\r\n","  return mean_absolute_error(ages_true, ages_pred)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"LC5QobhVH1cT","executionInfo":{"status":"ok","timestamp":1610038996549,"user_tz":-60,"elapsed":1631,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["# model compiling\r\n","from keras.regularizers import l2 \r\n","from keras.optimizers import SGD\r\n","\r\n","model=initial_model\r\n","weight_decay = 0.005 \r\n","for layer in model.layers:\r\n","    if isinstance(layer, keras.layers.Conv2D) and not isinstance(layer, keras.layers.DepthwiseConv2D) or isinstance(\r\n","            layer, keras.layers.Dense):\r\n","        layer.add_loss(lambda: l2(weight_decay)(layer.kernel))\r\n","    if hasattr(layer, 'bias_regularizer') and layer.use_bias:\r\n","        layer.add_loss(lambda: l2(weight_decay)(layer.bias))\r\n","optimizer = SGD(momentum=0.9)\r\n","\r\n","loss = keras.losses.categorical_crossentropy \r\n","accuracy_metrics = [keras.metrics.categorical_accuracy,mae] \r\n","model.compile(loss=loss, optimizer=optimizer, metrics=accuracy_metrics)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ih8_ywjOpd8","executionInfo":{"status":"ok","timestamp":1610038999380,"user_tz":-60,"elapsed":1953,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["def step_decay_schedule(initial_lr, decay_factor, step_size):\r\n","    def schedule(epoch):\r\n","        return initial_lr * (decay_factor ** np.floor(epoch / step_size))\r\n","\r\n","    return keras.callbacks.LearningRateScheduler(schedule, verbose=1)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKP4WzOGO1kb","executionInfo":{"status":"ok","timestamp":1610039005024,"user_tz":-60,"elapsed":1427,"user":{"displayName":"Kristian Colucci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghfj5G5RLEOxa5nC5OYvHd8Ad3jDzhLQ3DFnsl_=s64","userId":"13690252087596821606"}}},"source":["lr_sched = step_decay_schedule(initial_lr=0.005,decay_factor=0.2, step_size=20)\r\n","monitor = 'val_mae' \r\n","checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Final_Artificial_Vision/CNN/mobileNet_70TFRecords.h5', verbose=1, save_best_only=True, monitor=monitor)\r\n","callbacks_list = [lr_sched, checkpoint]#, tbCallBack]"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"tD9xk5iw779P"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dW_wWKfPnKrb"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"ClCSxg1OnKrb"},"source":["\n","history = model.fit(\n","    train_dataset,\n","    epochs=30,\n","    validation_data=valid_dataset,\n","    callbacks=callbacks_list,\n",")"],"execution_count":null,"outputs":[]}]}